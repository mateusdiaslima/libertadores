---
title: "Análise de dados sobre a Copa Libertadores da América"
author: ""
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Para começar, são necessários três pacotes: rvest e httr para extrair os dados da web, e tidyverse para manipular os dados, uma vez que eles já estão em nosso workspace.

```{r, message=FALSE}
library(tidyverse)
library(rvest)
library(httr)
```

- Extraindo os dados para a primeira edição do torneio

Os dados sobre os times classificados para a libertadores no ano de 1960 estão na url https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_1960.

![Página da competição no ano de 1960, onde a tabela com o título "Equipes Classificadas" é a que importamos para as análises.](Imagens/libertadores 1960.png){width=80%}

Ao clicar com o botão direito do mouse e selecionar a opção Inspecionar, o XPath da tabela é dado por //*[@id="mw-content-text"]/div[1]/table[2]

![Copiano o XPath da tabela.](Imagens/Xpath 1960.png){width=80%}

Com essas informações, importamos a tabela com o comando abaixo.

```{r}
url = ('https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_1960')

resultado = url %>%
  read_html() %>%
  html_nodes(xpath = '//*[@id="mw-content-text"]/div[1]/table[2]') %>% 
  html_table()
```

O valor que é armazenado na variável resultado é uma lista com um elemento, onde esse elemento é a tabela.

```{r}
resultado[[1]][,1:3] # exibindo as 3 primeiras colunas
```

Para o objetivo desse projeto, só as colunas País e Equipe são necessárias. Logo, selecionamos essas duas colunas e armazenamos no objeto tabela. Por simplicidade, os nomes das colunas ficarão com todas as letras em minúsculo e sem acentuação. Além disso, adicionamos uma coluna referente ao ano em que ocorreu o torneio. Isso é importante, pois quando unirmos as tabelas de todas as edições do torneio, queremos saber qual foi o ano em que determinado clube se classificou para a libertadores.

```{r}
tabela = resultado[[1]] %>% select(País, Equipe)
colnames(tabela) = c("pais", "equipe")
no_equipes = nrow(tabela) # número de equipes classificadas
edicao = rep(1960, no_equipes)
tabela = cbind(edicao, tabela) # adicionando a coluna edicao
```

Ao contruir os gráficos, é conveniente que os valores na coluna pais estejam sem os parenteses e a informação contida nos parenteses, ou seja, só o nome do país.
Uma solução, retirada do stackoverflow, é a seguinte:

```{r}
tabela$pais = gsub("\\s*\\([^\\)]+\\)","",as.character(tabela$pais))
tabela
```

A tarefa agora é extrair as tabelas para todas as edições do torneio e deixar no formato acima.

Seria interessante podermos generalizar o algoritmo acima para extrair a tabela dos outros anos. No entanto, não seria produtivo analisar as páginas do Wikipedia para cada ano manualmente a fim de encontrar um padrão entre elas, pois temos mais de 40 páginas. Temos que encontrar uma maneira sistemática de fazer isso. Como usamos apenas duas informações para importar a tabela, url da página e XPath da tabela, precisamos encontrar uma forma de generalizar nosso código a partir desses dois elementos.

- Analise da url

Vamos usar a página do torneio no ano de 2020 para comparar com a página do ano de 1960.

1960: https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_1960

2020: https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_2020

Comparando as duas urls, o que difere são os 4 últimos dígitos, ao qual se referem ao ano em questão. Logo, supomos que a url para acessar a página do torneio de qualquer ano é https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_xxxx, onde xxxx é substituído pelo ano que queremos analisar.

Com isso, vamos verificar se conseguimos conectar com as url's de cada ano. O código abaixo faz essa tarefa.

```{r}
for (ano in 1960:2020) {
    url = paste0('https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_', ano)
    url %>% read_html()
}
```

O código não retornou nenhum erro, o que indica que todas as url's são válidas.

- Análise do XPath

A tabela dos times classificados em 1960 tem XPath  //*[@id="mw-content-text"]/div[1]/table[2]. Para o ano de 1961, o mesmo Xpath. Com isso, a estratégia é verificar se a tabela para todos os anos tem o mesmo Xpath.
Criamos um vetor vazio anos, onde armazenamos no vetor cada ano antes de importar a tabela.

```{r, eval = FALSE}
anos = numeric(0)
for (ano in 1960:2020) {
    anos = c(anos, ano) # adicionando o ano no vetor anos 
    url = paste0('https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_', ano)
    resultado = url %>% read_html() %>%
    html_nodes(xpath = '//*[@id="mw-content-text"]/div[1]/table[2]') %>% 
    html_table()
}
```

O algoritmo retornou erro, o que significa que, para algum ano, o Xpath da tabela não é o mesmo que em 1960. Analisando o algoritmo, esse ano é o último elemento do vetor anos.

```{r, eval = FALSE}
last(anos) # extraindo último elemento
```

O algoritmo não conseguiu extrair a tabela para o ano de 1976. Antes da avaliar separadamente esse caso, vamos verificar os anos restantes.

```{r, eval = FALSE}
for (ano in 1960:2020) {
    url = paste0('https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_', ano)
    resultado = try(url %>% read_html() %>%
    html_nodes(xpath = '//*[@id="mw-content-text"]/div[1]/table[2]') %>% 
    html_table())
    if(inherits(resultado, "try-error")) {
      anos = c(anos, ano) # adicionando o ano no vetor anos
    }
    # anos = c(anos, ano) # adicionando o ano no vetor anos 
}
anos
```

O Xpath da tabela para o ano de 1976 é //*[@id="mw-content-text"]/div[1]/table[3]. Seguindo o mesmo raciocínio acima, vamos ver quais anos que também tem esse valor de Xpath.

```{r, eval = FALSE}
aux = numeric(0)
for (ano in anos) {
    url = paste0('https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_', ano)
    resultado = try(url %>% read_html() %>%
    html_nodes(xpath = '//*[@id="mw-content-text"]/div[1]/table[3]') %>% 
    html_table())
    if(inherits(resultado, "try-error")) {
      aux = c(aux, ano) # adicionando o ano no vetor anos
    }
    # anos = c(anos, ano) # adicionando o ano no vetor anos 
}
aux
```

Sobraram dois anos: 1980 e 1993. Além disso, a mensagem de erro é diferente que os casos anteriores. Para entender melhor, analisamos a tabela do ano de 1980. Acontece que a tabela tem um formato diferente. Com isso, temos que adotar outra estratégia para importar essa tabela.

Com a tabela nesse formato, não conseguimos importar de uma vez para todos os países. Logo, importamos para cada país separadamente e agrupamos em uma única tabela. Além disso, importamos cada tabela no formato texto, pois nosso algoritmo não importa como tabela.

```{r, eval = FALSE}
url = ('https://pt.wikipedia.org/wiki/Copa_Libertadores_da_Am%C3%A9rica_de_1980#Primeira_fase')

resultado = url %>%
  read_html() %>%
  html_nodes(xpath = '//*[@id="mw-content-text"]/div[1]/table[3]') %>%
  html_text()

resultado[[1]]
```



```{r, eval = FALSE}
start <- gsub("\\n\n","~~",as.character(resultado[[1]])) 

dat <- map(start, function(x) {
  tibble(text = unlist(str_split(x, pattern = "\\n"))) %>%
    rowid_to_column(var = "line")
})

tabela_aux = as.data.frame(dat[[1]] %>% select(text))
pais = rep(tabela_aux[1,1], nrow(tabela_aux))
```














